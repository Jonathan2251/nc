% Generated by Sphinx.
\def\sphinxdocclass{report}
\documentclass[letterpaper,10pt,english]{sphinxmanual}
\usepackage{iftex}

\ifPDFTeX
  \usepackage[utf8]{inputenc}
\fi
\ifdefined\DeclareUnicodeCharacter
  \DeclareUnicodeCharacter{00A0}{\nobreakspace}
\fi
\usepackage{cmap}
\usepackage[T1]{fontenc}
\usepackage{amsmath,amssymb,amstext}
\usepackage{babel}
\usepackage{times}
\usepackage[Bjarne]{fncychap}
\usepackage{longtable}
\usepackage{sphinx}
\usepackage{multirow}
\usepackage{eqparbox}


\addto\captionsenglish{\renewcommand{\figurename}{Fig.\@ }}
\addto\captionsenglish{\renewcommand{\tablename}{Table }}
\SetupFloatingEnvironment{literal-block}{name=Listing }

\addto\extrasenglish{\def\pageautorefname{page}}

\setcounter{tocdepth}{0}


\title{Neural Processor Unit Compiler}
\date{May 24, 2020}
\release{0.1}
\author{Chen Chung-Shu}
\newcommand{\sphinxlogo}{}
\renewcommand{\releasename}{Release}
\makeindex

\makeatletter
\def\PYG@reset{\let\PYG@it=\relax \let\PYG@bf=\relax%
    \let\PYG@ul=\relax \let\PYG@tc=\relax%
    \let\PYG@bc=\relax \let\PYG@ff=\relax}
\def\PYG@tok#1{\csname PYG@tok@#1\endcsname}
\def\PYG@toks#1+{\ifx\relax#1\empty\else%
    \PYG@tok{#1}\expandafter\PYG@toks\fi}
\def\PYG@do#1{\PYG@bc{\PYG@tc{\PYG@ul{%
    \PYG@it{\PYG@bf{\PYG@ff{#1}}}}}}}
\def\PYG#1#2{\PYG@reset\PYG@toks#1+\relax+\PYG@do{#2}}

\expandafter\def\csname PYG@tok@gd\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.63,0.00,0.00}{##1}}}
\expandafter\def\csname PYG@tok@gu\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.50,0.00,0.50}{##1}}}
\expandafter\def\csname PYG@tok@gt\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.00,0.27,0.87}{##1}}}
\expandafter\def\csname PYG@tok@gs\endcsname{\let\PYG@bf=\textbf}
\expandafter\def\csname PYG@tok@gr\endcsname{\def\PYG@tc##1{\textcolor[rgb]{1.00,0.00,0.00}{##1}}}
\expandafter\def\csname PYG@tok@cm\endcsname{\let\PYG@it=\textit\def\PYG@tc##1{\textcolor[rgb]{0.25,0.50,0.56}{##1}}}
\expandafter\def\csname PYG@tok@vg\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.73,0.38,0.84}{##1}}}
\expandafter\def\csname PYG@tok@vi\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.73,0.38,0.84}{##1}}}
\expandafter\def\csname PYG@tok@mh\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.13,0.50,0.31}{##1}}}
\expandafter\def\csname PYG@tok@cs\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.25,0.50,0.56}{##1}}\def\PYG@bc##1{\setlength{\fboxsep}{0pt}\colorbox[rgb]{1.00,0.94,0.94}{\strut ##1}}}
\expandafter\def\csname PYG@tok@ge\endcsname{\let\PYG@it=\textit}
\expandafter\def\csname PYG@tok@vc\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.73,0.38,0.84}{##1}}}
\expandafter\def\csname PYG@tok@il\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.13,0.50,0.31}{##1}}}
\expandafter\def\csname PYG@tok@go\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.20,0.20,0.20}{##1}}}
\expandafter\def\csname PYG@tok@cp\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@gi\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.00,0.63,0.00}{##1}}}
\expandafter\def\csname PYG@tok@gh\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.00,0.00,0.50}{##1}}}
\expandafter\def\csname PYG@tok@ni\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.84,0.33,0.22}{##1}}}
\expandafter\def\csname PYG@tok@nl\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.00,0.13,0.44}{##1}}}
\expandafter\def\csname PYG@tok@nn\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.05,0.52,0.71}{##1}}}
\expandafter\def\csname PYG@tok@no\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.38,0.68,0.84}{##1}}}
\expandafter\def\csname PYG@tok@na\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.25,0.44,0.63}{##1}}}
\expandafter\def\csname PYG@tok@nb\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@nc\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.05,0.52,0.71}{##1}}}
\expandafter\def\csname PYG@tok@nd\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.33,0.33,0.33}{##1}}}
\expandafter\def\csname PYG@tok@ne\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@nf\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.02,0.16,0.49}{##1}}}
\expandafter\def\csname PYG@tok@si\endcsname{\let\PYG@it=\textit\def\PYG@tc##1{\textcolor[rgb]{0.44,0.63,0.82}{##1}}}
\expandafter\def\csname PYG@tok@s2\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.25,0.44,0.63}{##1}}}
\expandafter\def\csname PYG@tok@nt\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.02,0.16,0.45}{##1}}}
\expandafter\def\csname PYG@tok@nv\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.73,0.38,0.84}{##1}}}
\expandafter\def\csname PYG@tok@s1\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.25,0.44,0.63}{##1}}}
\expandafter\def\csname PYG@tok@ch\endcsname{\let\PYG@it=\textit\def\PYG@tc##1{\textcolor[rgb]{0.25,0.50,0.56}{##1}}}
\expandafter\def\csname PYG@tok@m\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.13,0.50,0.31}{##1}}}
\expandafter\def\csname PYG@tok@gp\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.78,0.36,0.04}{##1}}}
\expandafter\def\csname PYG@tok@sh\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.25,0.44,0.63}{##1}}}
\expandafter\def\csname PYG@tok@ow\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@sx\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.78,0.36,0.04}{##1}}}
\expandafter\def\csname PYG@tok@bp\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@c1\endcsname{\let\PYG@it=\textit\def\PYG@tc##1{\textcolor[rgb]{0.25,0.50,0.56}{##1}}}
\expandafter\def\csname PYG@tok@o\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PYG@tok@kc\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@c\endcsname{\let\PYG@it=\textit\def\PYG@tc##1{\textcolor[rgb]{0.25,0.50,0.56}{##1}}}
\expandafter\def\csname PYG@tok@mf\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.13,0.50,0.31}{##1}}}
\expandafter\def\csname PYG@tok@err\endcsname{\def\PYG@bc##1{\setlength{\fboxsep}{0pt}\fcolorbox[rgb]{1.00,0.00,0.00}{1,1,1}{\strut ##1}}}
\expandafter\def\csname PYG@tok@mb\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.13,0.50,0.31}{##1}}}
\expandafter\def\csname PYG@tok@ss\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.32,0.47,0.09}{##1}}}
\expandafter\def\csname PYG@tok@sr\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.14,0.33,0.53}{##1}}}
\expandafter\def\csname PYG@tok@mo\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.13,0.50,0.31}{##1}}}
\expandafter\def\csname PYG@tok@kd\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@mi\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.13,0.50,0.31}{##1}}}
\expandafter\def\csname PYG@tok@kn\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@cpf\endcsname{\let\PYG@it=\textit\def\PYG@tc##1{\textcolor[rgb]{0.25,0.50,0.56}{##1}}}
\expandafter\def\csname PYG@tok@kr\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@s\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.25,0.44,0.63}{##1}}}
\expandafter\def\csname PYG@tok@kp\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@w\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.73,0.73,0.73}{##1}}}
\expandafter\def\csname PYG@tok@kt\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.56,0.13,0.00}{##1}}}
\expandafter\def\csname PYG@tok@sc\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.25,0.44,0.63}{##1}}}
\expandafter\def\csname PYG@tok@sb\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.25,0.44,0.63}{##1}}}
\expandafter\def\csname PYG@tok@k\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@se\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.25,0.44,0.63}{##1}}}
\expandafter\def\csname PYG@tok@sd\endcsname{\let\PYG@it=\textit\def\PYG@tc##1{\textcolor[rgb]{0.25,0.44,0.63}{##1}}}

\def\PYGZbs{\char`\\}
\def\PYGZus{\char`\_}
\def\PYGZob{\char`\{}
\def\PYGZcb{\char`\}}
\def\PYGZca{\char`\^}
\def\PYGZam{\char`\&}
\def\PYGZlt{\char`\<}
\def\PYGZgt{\char`\>}
\def\PYGZsh{\char`\#}
\def\PYGZpc{\char`\%}
\def\PYGZdl{\char`\$}
\def\PYGZhy{\char`\-}
\def\PYGZsq{\char`\'}
\def\PYGZdq{\char`\"}
\def\PYGZti{\char`\~}
% for compatibility with earlier versions
\def\PYGZat{@}
\def\PYGZlb{[}
\def\PYGZrb{]}
\makeatother

\renewcommand\PYGZsq{\textquotesingle}

\begin{document}

\maketitle
\tableofcontents
\phantomsection\label{index::doc}



\chapter{Deep learning model}
\label{model::doc}\label{model:deep-learning-model}\label{model:table-of-contents}\label{model:sec-model}
\begin{SphinxShadowBox}
\begin{itemize}
\item {} 
\phantomsection\label{model:id5}{\hyperref[model:ai]{\crossref{AI}}}

\item {} 
\phantomsection\label{model:id6}{\hyperref[model:cnn]{\crossref{CNN}}}

\end{itemize}
\end{SphinxShadowBox}


\section{AI}
\label{model:ai}
Hung-Yi Lee's video \footnote[1]{\sphinxAtStartFootnote%
\url{https://www.youtube.com/watch?v=CXgbekl66jc\&list=PLJV\_el3uVTsPy9oCRY30oBPNLCo89yu49}
}.


\section{CNN}
\label{model:cnn}
CNN: They have applications in image and video recognition, recommender systems,
image classification, medical image analysis, natural language processing, and
financial time series \footnote[4]{\sphinxAtStartFootnote%
\url{https://en.wikipedia.org/wiki/Convolutional\_neural\_network}
}.

Concept about how to apply Convolution and MaxPool to getting features from image \footnote[2]{\sphinxAtStartFootnote%
\url{http://violin-tao.blogspot.com/2017/07/ml-convolutional-neural-network-cnn.html}
}.
Conv+MaxPool -\textgreater{} get features map and downsize image, more Conv+MaxPool can filter image and higher
level of features and downsize more image. CNN model used in image recognition.

Concept and data applying in Deap Learning for different models of CNN \footnote[3]{\sphinxAtStartFootnote%
\url{https://github.com/onnx/models}
}.


\chapter{NPU compiler}
\label{npu:sec-npu}\label{npu::doc}\label{npu:npu-compiler}
\begin{SphinxShadowBox}
\begin{itemize}
\item {} 
\phantomsection\label{npu:id10}{\hyperref[npu:npu\string-compiler\string-reference]{\crossref{NPU compiler reference}}}

\item {} 
\phantomsection\label{npu:id11}{\hyperref[npu:mlir\string-and\string-iree]{\crossref{MLIR and IREE}}}

\item {} 
\phantomsection\label{npu:id12}{\hyperref[npu:tensorflow]{\crossref{Tensorflow}}}

\item {} 
\phantomsection\label{npu:id13}{\hyperref[npu:mlir\string-to\string-onnx]{\crossref{mlir to onnx}}}

\item {} 
\phantomsection\label{npu:id14}{\hyperref[npu:llvm\string-ir\string-for\string-npu\string-compiler]{\crossref{llvm IR for NPU compiler}}}

\item {} 
\phantomsection\label{npu:id15}{\hyperref[npu:open\string-source\string-project]{\crossref{Open source project}}}

\end{itemize}
\end{SphinxShadowBox}


\section{NPU compiler reference}
\label{npu:npu-compiler-reference}
\url{https://arxiv.org/pdf/2002.03794.pdf}

Tensorflow support unknown shape \footnote[2]{\sphinxAtStartFootnote%
\url{https://pgaleone.eu/tensorflow/2018/07/28/understanding-tensorflow-tensors-shape-static-dynamic/}
}.
Though our npu support kernel call where kernel call is a set of
commands to npu to deal shape at run time, it is unefficiency.
As I remember mlit supports binding shape for unknown at compile-time
but not always work.
Lukily, we can customilze by redefining model to binding shape staticlly {[}20200412{]}.


\section{MLIR and IREE}
\label{npu:mlir-and-iree}
IREE (Intermediate Representation Execution Environment, pronounced as ``eerie'')
is an MLIR-based end-to-end compiler that lowers ML models to a unified IR
optimized for real-time mobile/edge inference against heterogeneous hardware
accelerators. IREE also provides flexible deployment solutions for the compiled
ML models \footnote[1]{\sphinxAtStartFootnote%
\url{https://github.com/google/iree}
} as the following figure.
\phantomsection\label{npu:iree-f}\begin{figure}[htbp]
\centering

\scalebox{1.000000}{\includegraphics{{IREE-Architecture}.png}}
\label{npu:iree-f}\end{figure}
\begin{itemize}
\item {} 
HAL IR: Vulkan-like allocation and execution model encoding -\textgreater{} on-line first-time compilation and save in cache. Executable compilation via architecture specific backend compiler plugins.

\item {} 
VM IR: Dynamic module linkage definitions (imports, exports, globals, etc) \footnote[3]{\sphinxAtStartFootnote%
Page 15 of \url{https://docs.google.com/presentation/d/1RCQ4ZPQFK9cVgu3IH1e5xbrBcqy7d\_cEZ578j84OvYI/edit\#slide=id.g6e31674683\_0\_23101}
}.

\end{itemize}

The purpose of mlir is:
\begin{itemize}
\item {} 
Connect cpu with mlir-to-llvm-ir.

\end{itemize}

The purpose of iree is:
\begin{itemize}
\item {} 
Connect to gpu with iree-to-spirv.

\end{itemize}

Both purpose of mlir and iree is:
\begin{itemize}
\item {} 
Reduce bug and problem between heterogeneous hardware accelerators \footnote[4]{\sphinxAtStartFootnote%
\url{https://kknews.cc/zh-tw/tech/klkombr.html}
}.

\end{itemize}


\section{Tensorflow}
\label{npu:tensorflow}
The mechansim of Mlir and iree applied on tensorflow as the figure above section
is not fitted for off-line edge npu that stand alone without server-connection
for tunning weight of face detection's purpose.
It is designed for on-line server-connected npu.
The gpu of supporting spirv is best candidate until this date 2020/5/12.

At beginning, tensorflow rely on api without fixed format such as ONNX \footnote[5]{\sphinxAtStartFootnote%
Actually onnx format based on IO api with protobuffer. It has real binary format but may change from version to version. Tensorflow api has no real binary format.
}.
As a result ONNX emerged and adopted for most of npu in their private backend
compiler. Google does not like to hire onnx as the format for npu backend compiler
onnx-mlir project \footnote[6]{\sphinxAtStartFootnote%
\url{https://github.com/onnx/onnx-mlir}
} which convert onnx to mlir dialect is sponsored
by Google I guess \footnote[7]{\sphinxAtStartFootnote%
\url{https://groups.google.com/a/tensorflow.org/forum/\#!topic/mlir/2FT4sD8kqTY}
} for encourging new npu compiler
development hiring mlir as their compiler input (convert onnx to mlir then
handling mlir input).

With mlir and iree appear on tensorflow as a series of fixed formats in
tensorflow as section above. The hardware vendors for cloud server AI machine
with heterogeneous hardware accelerators will run tensorflow system
by supporting mlir/iree input format in their compilers more and more.
So, it is unavoidable that tensorflow system's npu vendors have to support
mlir/iree input format beyond onnx. Or open source software or vendor software
appear to do transfer from mlir/iree to onnx. (python in tensorflow api allow
unknown type and shape size, so it cannot transer python api to onnx fully).

If lucky, google may hire onnx. Because onnx format is older than mlir
in history. In addition in aspect of format, mlir has mult-level mult-dialect and
more complicate while onnx is easy and better to understand (P.S. I don't dig
into mlir yet).
Many AI models has supported onnx file format. For some AI model's formats that
run on tensorflow without supporting onnx, aplly tensorflow-onnx open
source project \footnote[8]{\sphinxAtStartFootnote%
\url{https://github.com/onnx/tensorflow-onnx}
} can convert tensorflow to onnx partly.

Onnx alliance may release some programs for transfering mlir to onnx for fighting
agiant mlir-iree growing in npu compiler but not at this moment.

For off-line edge npu that stand alone without server-connection
for tunning weight of face detection's purpose, supprting mlir-iree compiler
may not necessary.


\section{mlir to onnx}
\label{npu:mlir-to-onnx}
\url{https://www.tensorflow.org/mlir}

\url{https://mlir.llvm.org/talks/}

\url{https://llvm.org/devmtg/2019-04/talks.html\#Tutorial\_1}
\begin{itemize}
\item {} 
3 ppt in llvm tutorials

\end{itemize}

\url{https://llvm.org/devmtg/2019-04/slides/Tutorial-AminiVasilacheZinenko-MLIR.pdf}

build mlir: \url{https://mlir.llvm.org/getting\_started/}

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{g+go}{\PYGZti{}/llvm/1/llvm\PYGZhy{}project/build\PYGZdl{} cmake \PYGZhy{}G Ninja ../llvm \PYGZbs{}}
\PYG{g+gp}{\PYGZgt{}}    \PYGZhy{}DLLVM\PYGZus{}ENABLE\PYGZus{}PROJECTS\PYG{o}{=}mlir \PYG{l+s+se}{\PYGZbs{}}
\PYG{g+gp}{\PYGZgt{}}    \PYGZhy{}DLLVM\PYGZus{}BUILD\PYGZus{}EXAMPLES\PYG{o}{=}ON \PYG{l+s+se}{\PYGZbs{}}
\PYG{g+gp}{\PYGZgt{}}    \PYGZhy{}DLLVM\PYGZus{}TARGETS\PYGZus{}TO\PYGZus{}BUILD\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}X86;NVPTX;AMDGPU\PYGZdq{}} \PYG{l+s+se}{\PYGZbs{}}
\PYG{g+gp}{\PYGZgt{}}    \PYGZhy{}DCMAKE\PYGZus{}BUILD\PYGZus{}TYPE\PYG{o}{=}Release \PYG{l+s+se}{\PYGZbs{}}
\PYG{g+gp}{\PYGZgt{}}    \PYGZhy{}DLLVM\PYGZus{}ENABLE\PYGZus{}ASSERTIONS\PYG{o}{=}ON

\PYG{g+go}{\PYGZti{}/llvm/1/llvm\PYGZhy{}project/build\PYGZdl{} cmake \PYGZhy{}\PYGZhy{}build . \PYGZhy{}\PYGZhy{}target check\PYGZhy{}mlir}
\PYG{g+go}{[200/1919] Generating VCSRevision.h}
\PYG{g+go}{\PYGZhy{}\PYGZhy{} Found Git: /usr/bin/git (found version \PYGZdq{}2.17.1\PYGZdq{})}
\PYG{g+go}{[1604/1919] Building CXX object tools/mlir/tools/mlir\PYGZhy{}linalg\PYGZhy{}ods\PYGZhy{}gen/CMakeFiles/mlir\PYGZhy{}linalg\PYGZhy{}ods\PYGZhy{}gen.dir/mlir\PYGZhy{}linalg\PYGZhy{}ods\PYGZhy{}gen.cpp.o}
\PYG{g+go}{/home/cschen/llvm/1/llvm\PYGZhy{}project/mlir/tools/mlir\PYGZhy{}linalg\PYGZhy{}ods\PYGZhy{}gen/mlir\PYGZhy{}linalg\PYGZhy{}ods\PYGZhy{}gen.cpp:935:6: warning: ‘bool \PYGZob{}anonymous\PYGZcb{}::Expression::operator==(const \PYGZob{}anonymous\PYGZcb{}::Expression\PYGZam{}) const’ defined but not used [\PYGZhy{}Wunused\PYGZhy{}function]}
\PYG{g+go}{ bool Expression::operator==(const Expression \PYGZam{}e) const \PYGZob{}}
\PYG{g+go}{      \PYGZca{}\PYGZti{}\PYGZti{}\PYGZti{}\PYGZti{}\PYGZti{}\PYGZti{}\PYGZti{}\PYGZti{}\PYGZti{}}
\PYG{g+go}{[1918/1919] Running the MLIR regression tests}

\PYG{g+go}{Testing Time: 9.88s}
\PYG{g+go}{  Unsupported Tests:  16}
\PYG{g+go}{  Expected Passes  : 465}
\end{Verbatim}

run: \url{https://mlir.llvm.org/docs/Tutorials/Toy/}

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{g+go}{\PYGZti{}/llvm/1/llvm\PYGZhy{}project/mlir/test/Examples/Toy/Ch1\PYGZdl{} \PYGZti{}/llvm/1/llvm\PYGZhy{}project/build/bin/toyc\PYGZhy{}ch1 ast.toy \PYGZhy{}emit=ast}
\PYG{g+go}{...}
\PYG{g+go}{\PYGZti{}/llvm/1/llvm\PYGZhy{}project/mlir/test/Examples/Toy/Ch1\PYGZdl{} \PYGZti{}/llvm/1/llvm\PYGZhy{}project/build/bin/toyc\PYGZhy{}ch1 ast.toy \PYGZhy{}emit=ast 2\PYGZgt{}\PYGZam{}1 \textbar{} \PYGZti{}/llvm/1/llvm\PYGZhy{}project/build/bin/FileCheck ast.toy}
\PYG{g+go}{\PYGZti{}/llvm/1/llvm\PYGZhy{}project/mlir/test/Examples/Toy/Ch1\PYGZdl{} \PYGZti{}/llvm/1/llvm\PYGZhy{}project/build/bin/llvm\PYGZhy{}lit ast.toy}
\PYG{g+go}{\PYGZhy{}\PYGZhy{} Testing: 1 tests, 1 workers \PYGZhy{}\PYGZhy{}}
\PYG{g+go}{PASS: MLIR :: Examples/Toy/Ch1/ast.toy (1 of 1)}

\PYG{g+go}{Testing Time: 0.11s}
\PYG{g+go}{  Expected Passes: 1}
\end{Verbatim}

The result I run is based on git commit 455ccde1377b3ec32d321eb7c38808fecdf230a8 Date:   Sun May 17 21:00:09 2020 -0400


\section{llvm IR for NPU compiler}
\label{npu:llvm-ir-for-npu-compiler}
Though npu has no general purpose registers GPR, it is possible to apply llvm ir for
npu to do codegen by llvm as follows,
\begin{figure}[htbp]
\centering
\capstart

\scalebox{1.000000}{\includegraphics{{conv_onnx}.png}}
\caption{Conv operation in onnx file}\label{npu:conv}\label{npu:id9}\end{figure}

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{n+nv+vg}{@weight} \PYG{p}{=} \PYG{k}{global} \PYG{p}{[}\PYG{l+m}{46} \PYG{k}{x} \PYG{l+m}{1} \PYG{k}{x} \PYG{l+m}{5} \PYG{p}{[}\PYG{l+m}{5} \PYG{k}{x} \PYG{k+kt}{float}\PYG{p}{]}\PYG{p}{]} \PYG{p}{[}\PYG{p}{[}\PYG{p}{[}\PYG{p}{[}\PYG{l+m}{5} \PYG{k}{x} \PYG{k+kt}{float}\PYG{p}{]} \PYG{p}{[}\PYG{k+kt}{float} \PYG{l+m}{0.05475775524973869}\PYG{p}{,} \PYG{p}{.}\PYG{p}{.}\PYG{p}{.}\PYG{p}{]}\PYG{p}{,} \PYG{p}{[}\PYG{l+m}{5} \PYG{k}{x} \PYG{k+kt}{float}\PYG{p}{]} \PYG{p}{[}\PYG{k+kt}{float} \PYG{p}{.}\PYG{p}{.}\PYG{p}{.}\PYG{p}{]}\PYG{p}{]}\PYG{p}{,} \PYG{p}{.}\PYG{p}{.}\PYG{p}{.}\PYG{p}{]}
\PYG{n+nv+vg}{@conv} \PYG{p}{=} \PYG{n+nv+vg}{@llvm.npu1.conv} \PYG{k+kt}{float}\PYG{p}{*} \PYG{n+nv+vg}{@input}\PYG{p}{,} \PYG{k+kt}{float}\PYG{p}{*} \PYG{n+nv+vg}{@weight}\PYG{p}{,} \PYG{p}{.}\PYG{p}{.}\PYG{p}{.}
\end{Verbatim}

Conclusion: Data definition too much and no GPR. Not worth to hire llvm.


\section{Open source project}
\label{npu:open-source-project}\begin{itemize}
\item {} 
onnx to mlir dialect: \url{https://github.com/onnx/onnx-mlir}

\item {} 
tensorflow to onnx: \url{https://github.com/onnx/tensorflow-onnx}

\item {} 
onnx to tensorflow: \url{https://github.com/onnx/onnx-tensorflow}

\end{itemize}


\chapter{Alternate formats}
\label{index:alternate-formats}
The book is also available in the following formats:


\chapter{Search this website}
\label{index:search-this-website}\begin{itemize}
\item {} 
\DUrole{xref,std,std-ref}{search}

\end{itemize}



\renewcommand{\indexname}{Index}
\printindex
\end{document}
